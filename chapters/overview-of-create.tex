\chapter{Overview Of CREATE}\label{sec:overview}
Figure~\ref{fig:arch} describes the 6 parts of \CREATE.
We provide brief overviews of the individual components of \CREATE\  below.

%Because the data ingestion phase is relatively straightforward (but tedious), we do not describe it %below. The remaining 5 components are:

\begin{enumerate}
\item \textsf{Data Ingestion} - a fairly straightforward, if tedious process
of converting the XML data files provided to us into case $\times$ feature matrices.
We limit our discussion of this step to what was presented in 
Section \ref{sec:challenge}, when we discussed the provided dataset.

 \item \textsf{Feature Extraction} - described in Section \ref{sec:features}.  We started our work on predicting the \textsf{Valence} variable by careful
extraction of existing features from the raw XML data provided to us by the  organizers.
After starting with the features present verbatim (i.e.,
as unique elements) in the released dataset (see Table \ref{tab:data2}) we defined several other features to generate
a single overarching dataset.

 \item \textsf{Development of Association Rule-based Features} - described in Section~\ref{sec:assoc-rules}. In this stage, we extracted a set of 345,373 Class Association Rules from the above dataset and then eliminated redundant ones to generate a total of 628 in all. For
 each retained Class Association Rule we included a binary feature into our dataset.
 
 \item \textsf{Feature Selection} - described in Section \ref{sec:selection}. We next devised a set of tests to identify irrelevant features; a feature that failed all of the tests was eliminated.
 
 \item \textsf{Classifier Development \&\ Training} - described in Section \ref{sec:ml}. 
We devised seven different views of our data: each view containing a specific subset of the
full set of features. We put together a battery of 22 machine learning algorithms,
including two novel adaptations of Random Forests and AdaBoost that we developed.
We trained the 22 classifiers on our seven data views and selected the best runs
for the ensemble learning step.

 \item \textsf{Ensemble Learning} - described in Section \ref{sec:ensembles}. On the
 last step, we evaluated ensembles of best-performing individual classifiers. 
 We used both simple majority/plurality ensemble schemes, as well as more complicated voting
techniques to see which, if any, provided the best solutions.
At the end, a number of \textit{simple} ensembles over subsets of our classifiers emerged with scores
that were clear improvements over the best  individual classifiers, and produced \textsf{MA-MAE} scores over 0.86.  From those, we selected three predictors that we submitted
to the N-GRID  challenge organizers.  
We were glad and proud to discover that one of our submissions had the
highest overall \textsf{MA-MAE} among the submitted solutions.
\end{enumerate}

